{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "innoplexus.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xooca/simpletorch/blob/master/innoplexus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYfgPRPyLm2_",
        "colab_type": "code",
        "outputId": "d36ba9ae-340f-49db-f3bd-743a2a09c59f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Hu!pip install overrides\n",
        "!pip install allennlp\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (0.8.4)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.0)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.1)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.13.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.6.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.21.2)\n",
            "Requirement already satisfied: conllu==0.11 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.11)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from allennlp) (5.5.1)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.0)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.4)\n",
            "Requirement already satisfied: spacy<2.2,>=2.0.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.1.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.189)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.3)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.8)\n",
            "Requirement already satisfied: awscli>=1.11.91 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.207)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.10.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from parsimonious>=0.8.0->allennlp) (1.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2019.6.8)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (2.10.1)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp) (0.13.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.6.16)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.0.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.2.2)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (2.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.0.18->allennlp) (0.2.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.189 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.12.197)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.7.1)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n",
            "Requirement already satisfied: PyYAML<=5.1,>=3.10; python_version != \"2.6\" in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.13)\n",
            "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.4.2)\n",
            "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.3.9)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (0.15.5)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (7.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.1.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (41.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp) (1.1.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.9.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.7.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (19.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDWDb9JAP4DF",
        "colab_type": "code",
        "outputId": "eb46454e-2639-44c9-f3b2-62f66d4e8836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from pathlib import Path\n",
        "from typing import *\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from functools import partial\n",
        "from overrides import overrides\n",
        "\n",
        "from allennlp.data import Instance\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "from allennlp.nn import util as nn_util\n",
        "from nltk.tokenize import TreebankWordTokenizer, word_tokenize, sent_tokenize\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_auc_score\n",
        "import string\n",
        "import nltk\n",
        "import re\n",
        "from collections import Counter\n",
        "import gensim\n",
        "from allennlp.training.trainer import Trainer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.data.dataset_readers import DatasetReader\n",
        "from allennlp.data.fields import TextField, MetadataField, ArrayField\n",
        "from allennlp.common.checks import ConfigurationError\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder\n",
        "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
        "from allennlp.modules.token_embedders.bert_token_embedder import PretrainedBertEmbedder\n",
        "from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper\n",
        "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
        "from allennlp.data.token_indexers import SingleIdTokenIndexer\n",
        "from allennlp.data.token_indexers import PretrainedBertIndexer\n",
        "from allennlp.training.metrics import auc,categorical_accuracy,f1_measure\n",
        "from allennlp.training.learning_rate_schedulers import learning_rate_scheduler ,CosineWithRestarts\n",
        "from allennlp.training.momentum_schedulers import momentum_scheduler,inverted_triangular\n",
        "from allennlp.training.learning_rate_schedulers import noam,NoamLR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr74jb2fQeBY",
        "colab_type": "code",
        "outputId": "42867b32-ef9a-41c1-82d3-2e67c38ce3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkwCn3e46P65",
        "colab_type": "code",
        "outputId": "06a5aa72-0be3-4eb1-c6a5-b04e220833eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ14gx1K7Whn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = pd.read_csv('/content/gdrive/My Drive/Studies/innoplexus/sample_submission_i5xnIZD.csv')\n",
        "test = pd.read_csv('/content/gdrive/My Drive/Studies/innoplexus/test_tOlRoBf.csv')\n",
        "train = pd.read_csv('/content/gdrive/My Drive/Studies/innoplexus/train_F3WbcTw.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V9wBNjfZ7il",
        "colab_type": "code",
        "outputId": "f3f44290-f5eb-4b5b-f932-76cbf78be13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5279, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkmMaOU87n2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_validate_test_split(df, train_percent=.8, validate_percent=.2, seed=None):\n",
        "    np.random.seed(seed)\n",
        "    perm = np.random.permutation(df.index)\n",
        "    m = len(df.index)\n",
        "    train_end = int(train_percent * m)\n",
        "    train_end = train_end +1\n",
        "    validate_end = int(validate_percent * m) + train_end\n",
        "    print(train_end)\n",
        "    print(validate_end)\n",
        "    train = df.ix[perm[:train_end]]\n",
        "    validate = df.ix[perm[train_end:validate_end]]\n",
        "    return train, validate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNvnikREZ1jI",
        "colab_type": "code",
        "outputId": "348e182d-21d1-4df5-ade2-7ed1fcca51d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "train , validate = train_validate_test_split(train, train_percent=.8, validate_percent=.2, seed=None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4224\n",
            "5279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er-RXEymAROd",
        "colab_type": "code",
        "outputId": "aff6954a-f1fe-4bd6-9702-be8230f4ced6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train.shape,validate.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4224, 4), (1055, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBjNS4hod3Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "validate = validate.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oia1zTehAJpP",
        "colab_type": "code",
        "outputId": "998ef804-85bd-42c7-e248-c32a8053af08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "train['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3073\n",
              "1     668\n",
              "0     483\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgYWsxvAjpr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCPFVM-cjp3f",
        "colab_type": "code",
        "outputId": "610df580-64f0-4f2a-ae9b-70bdba46f133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "validate['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    752\n",
              "1    169\n",
              "0    134\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz2aZMmA7slm",
        "colab_type": "code",
        "outputId": "31b9b971-3f4f-443c-e5c2-5c844696477f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>256 (previously stable on natalizumab), with 5...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>On fingolimod and have been since December 201...</td>\n",
              "      <td>fingolimod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
              "      <td>Apparently it's shingles! :-/ I do have a few ...</td>\n",
              "      <td>humira</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
              "      <td>If the Docetaxel doing once a week x3 weeks th...</td>\n",
              "      <td>tagrisso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
              "      <td>CC, Stelara worked in a matter of days for me....</td>\n",
              "      <td>stelara</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ...        drug\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08  ...  fingolimod\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a  ...  fingolimod\n",
              "2  50b6d851bcff4f35afe354937949e9948975adf7  ...      humira\n",
              "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae  ...    tagrisso\n",
              "4  8b37d169dee5bdae27060949242fb54feb6a7f7f  ...     stelara\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tcpXxo57zFH",
        "colab_type": "code",
        "outputId": "b483ff80-9ef1-4d70-93ce-a52167ff7dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "sample.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  sentiment\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08          0\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a          0\n",
              "2  50b6d851bcff4f35afe354937949e9948975adf7          0\n",
              "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae          0\n",
              "4  8b37d169dee5bdae27060949242fb54feb6a7f7f          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW6ffNxQLso_",
        "colab_type": "code",
        "outputId": "a2b45189-6f4b-44a8-f3ba-c09fa0511286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import spacy\n",
        "print('spaCy Version: %s' % (spacy.__version__))\n",
        "spacy_nlp = spacy.load('en')\n",
        "\n",
        "\n",
        "def removestopwords_spacy(val):\n",
        "    spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "    doc = spacy_nlp(val)\n",
        "    tokens = [token.text for token in doc if not token.is_stop]\n",
        "    return ' '.join(tokens)\n",
        "  \n",
        "def lemmatizer(val):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_list = nltk.word_tokenize(val)\n",
        "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "    return lemmatized_output\n",
        "\n",
        "def lemmatizer_spacy(val):\n",
        "    doc = spacy_nlp(val)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    word_list = [token for token in doc] \n",
        "    lemmatized_output = ' '.join([w.lemma_ if w.lemma_ != '-PRON-' else w.lower_ for w in word_list])\n",
        "    #lemmatized_output = ' '.join([token.lemma_ for token in word_list])\n",
        "    return lemmatized_output\n",
        "\n",
        "def removenewline(val):\n",
        "    val = str(val).replace('\\n', ' ')\n",
        "    return val\n",
        "\n",
        "def removepunc(val):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return str(val).translate(translator)\n",
        "\n",
        "def removestopwords_nltk(val):\n",
        "    nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
        "    #stopwords_1= ['not','nor','no','against','before','after','down','again','out','more']\n",
        "    #for w in stopwords_1:\n",
        "    #    nltk_stopwords.remove(w)\n",
        "    tokens = nltk.tokenize.word_tokenize(val)\n",
        "    tokens = [token for token in tokens if not token in nltk_stopwords]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def removenonenglish(val):\n",
        "    printable = set(string.printable)\n",
        "    return ''.join(list(filter(lambda x: x in printable, val)))\n",
        "\n",
        "    \n",
        "def clean_data_level1(reviews,trainmode=True):\n",
        "    reviews['text_original'] = reviews['text']\n",
        "    reviews[\"text\"] = reviews['text'].str.replace('[^a-zA-Z]+',' ')\n",
        "    reviews[\"text\"] = reviews[\"text\"].apply(removenewline)\n",
        "    reviews[\"text\"] = reviews[\"text\"].apply(removenonenglish)\n",
        "    #reviews[\"text\"] = reviews[\"text\"].apply(spellcorrect)\n",
        "    reviews[\"text\"] = reviews[\"text\"].apply(removepunc)\n",
        "    reviews[\"text\"] = reviews[\"text\"].apply(lemmatizer_spacy)\n",
        "    #reviews[\"text\"] = reviews[\"text\"].apply(lemmatizer)\n",
        "    reviews[\"text\"] = reviews[\"text\"].apply(removestopwords_nltk)\n",
        "    #reviews[\"text\"] = reviews[\"text\"].apply(removestopwords_spacy)\n",
        "    reviews[\"text\"] = reviews[\"text\"].apply(lambda x:x.lower())\n",
        "    if trainmode:\n",
        "      reviews = converttodummies(reviews,['sentiment'],threshold=200)\n",
        "    reviews = reviews.reset_index(drop=True)\n",
        "    return reviews\n",
        "\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "from datetime import datetime\n",
        "def converttodummies(tmpdf,cols,skipcols=[],threshold=100):\n",
        "    #converttodummies_col = tmpdf.columns\n",
        "    try:\n",
        "        for col in cols:\n",
        "            if col not in skipcols:\n",
        "                if tmpdf[col].nunique() <= threshold:\n",
        "                    dummy = pd.get_dummies(tmpdf[col])\n",
        "                    dummy.columns = [col+'_'+str(x) for x in dummy.columns]\n",
        "                    tmpdf = pd.concat([tmpdf, dummy], axis=1)\n",
        "                    #tmpdf = tmpdf.drop(col,axis=1)\n",
        "                else:\n",
        "                    pass\n",
        "        return tmpdf\n",
        "    except:\n",
        "        sys.exit('ERROR : ' + str(datetime.now()) + ' : ' + sys.exc_info()[1])\n",
        "        \n",
        "def nullfinder(df):\n",
        "    for col in df:\n",
        "        if sum(df[col].isnull()) > 0:\n",
        "            print(f\"For {col} number of nulls are {sum(df[col].isnull())}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spaCy Version: 2.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYKGQZLlIkMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = clean_data_level1(train,trainmode=True)\n",
        "validate = clean_data_level1(validate,trainmode=True)\n",
        "test = clean_data_level1(test,trainmode=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN2DMKx9Lyyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SentiDatasetReader(DatasetReader):\n",
        "    def __init__(self,token_indexers,max_seq_len,review_column,id_column,label_column,istesting,embeddingtype='bert'):\n",
        "        super().__init__()\n",
        "        #self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "        #print(token_indexers)\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.review_column  = review_column\n",
        "        self.id_column = id_column\n",
        "        self.label_column = label_column\n",
        "        #self.token_indexers = ELMoTokenCharactersIndexer() \n",
        "        self.token_indexer = token_indexers\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.testing = istesting\n",
        "        if embeddingtype == 'elmo':\n",
        "            self.tokenizer = self.elmo_tokenizer\n",
        "        elif embeddingtype == 'bert':\n",
        "            self.tokenizer = self.bert_tokenizer\n",
        "        else:\n",
        "            self.tokenizer = SingleIdTokenIndexer()\n",
        "        self.token_indexers = {\"tokens\": self.token_indexer}\n",
        "    \n",
        "    def elmo_tokenizer(self,x):\n",
        "        return [w.text for w in\n",
        "                SpacyWordSplitter(language='en_core_web_sm', \n",
        "                                  pos_tags=False).split_words(x)[:self.max_seq_len]]\n",
        "    \n",
        "    def bert_tokenizer(self,x):\n",
        "        #print(self.token_indexer)\n",
        "        return self.token_indexer.wordpiece_tokenizer(x)[:self.max_seq_len - 2]\n",
        "    @overrides\n",
        "    def text_to_instance(self,tokens,id,labels):\n",
        "        \n",
        "        sentence_field = TextField(tokens, self.token_indexers)\n",
        "        fields = {\"tokens\": sentence_field}\n",
        "         \n",
        "        id_field = MetadataField(id)\n",
        "        fields[\"id\"] = id_field\n",
        "        if labels is None:\n",
        "            labels = np.zeros(len(label_cols))\n",
        "        label_field = ArrayField(array=labels)\n",
        "        fields[\"label\"] = label_field\n",
        "        return Instance(fields)\n",
        "    \n",
        "    @overrides\n",
        "    def _read(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        if self.testing: \n",
        "            df = df.head(1000)\n",
        "        for i, row in df.iterrows():\n",
        "          yield self.text_to_instance(\n",
        "              [Token(x) for x in self.tokenizer(str(row[self.review_column]))],\n",
        "              str(row[self.id_column]), \n",
        "              row[self.label_column].values,\n",
        "          )\n",
        "\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVdC9BXNNS5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SentiDatasetReaderTest(DatasetReader):\n",
        "    def __init__(self,token_indexers,max_seq_len,review_column,id_column,label_column,istesting,embeddingtype='bert'):\n",
        "        super().__init__()\n",
        "        #self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "        #print(token_indexers)\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.review_column  = review_column\n",
        "        self.id_column = id_column\n",
        "        self.label_column = label_column\n",
        "        #self.token_indexers = ELMoTokenCharactersIndexer() \n",
        "        self.token_indexer = token_indexers\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.testing = istesting\n",
        "        if embeddingtype == 'elmo':\n",
        "            self.tokenizer = self.elmo_tokenizer\n",
        "        elif embeddingtype == 'bert':\n",
        "            self.tokenizer = self.bert_tokenizer\n",
        "        else:\n",
        "            self.tokenizer = SingleIdTokenIndexer()\n",
        "        self.token_indexers = {\"tokens\": self.token_indexer}\n",
        "    \n",
        "    def elmo_tokenizer(self,x):\n",
        "        return [w.text for w in\n",
        "                SpacyWordSplitter(language='en_core_web_sm', \n",
        "                                  pos_tags=False).split_words(x)[:self.max_seq_len]]\n",
        "    \n",
        "    def bert_tokenizer(self,x):\n",
        "        #print(self.token_indexer)\n",
        "        return self.token_indexer.wordpiece_tokenizer(x)[:self.max_seq_len - 2]\n",
        "    @overrides\n",
        "    def text_to_instance(self,tokens,id,labels):\n",
        "        \n",
        "        sentence_field = TextField(tokens, self.token_indexers)\n",
        "        fields = {\"tokens\": sentence_field}\n",
        "         \n",
        "        id_field = MetadataField(id)\n",
        "        fields[\"id\"] = id_field\n",
        "        return Instance(fields)\n",
        "    \n",
        "    @overrides\n",
        "    def _read(self, file_path):\n",
        "        df = pd.read_csv(file_path)\n",
        "        if self.testing: \n",
        "            df = df.head(1000)\n",
        "        for i, row in df.iterrows():\n",
        "          yield self.text_to_instance(\n",
        "              [Token(x) for x in self.tokenizer(str(row[self.review_column]))],\n",
        "              str(row[self.id_column]), \n",
        "          )\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H49Po8PL1CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(dict):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        for k, v in kwargs.items():\n",
        "            setattr(self, k, v)\n",
        "    \n",
        "    def set(self, key, val):\n",
        "        self[key] = val\n",
        "        setattr(self, key, val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3mfSEjwLc3n",
        "colab_type": "code",
        "outputId": "357fc928-4c3d-48c5-cdcd-795eaab91e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>text</th>\n",
              "      <th>drug</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_original</th>\n",
              "      <th>sentiment_0</th>\n",
              "      <th>sentiment_1</th>\n",
              "      <th>sentiment_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4b45464468211e25b0ba095b7d9beee2f011939a</td>\n",
              "      <td>jan pm momcareteam write mom diagnose stage ns...</td>\n",
              "      <td>opdivo</td>\n",
              "      <td>2</td>\n",
              "      <td>On Jan 05, 2016 11:02 PM MomCareTeam wrote: My...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67a405445e3e2141895ca34318da9a02e9c2dde7</td>\n",
              "      <td>another reason win take ocrelizumab progressiv...</td>\n",
              "      <td>ocrelizumab</td>\n",
              "      <td>1</td>\n",
              "      <td>Another reason I won't be taking Ocrelizumab f...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5a99d2f82fdf8df4d715bb7e6620326a1ce8a112</td>\n",
              "      <td>peg brave try quite remedy already really good...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>0</td>\n",
              "      <td>Peg, you've been brave and tried quite a few r...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13f717b1740d24d4322ddf07f76e42e9f9b3f2cc</td>\n",
              "      <td>hello interesting appointment post ru cat wow ...</td>\n",
              "      <td>ocrevus</td>\n",
              "      <td>2</td>\n",
              "      <td>Hello, Such an interesting appointment and pos...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20bf0873a730336db54199689605645c5f2dc6c3</td>\n",
              "      <td>confused ocrelizumab clone rituximab see many ...</td>\n",
              "      <td>ocrelizumab</td>\n",
              "      <td>2</td>\n",
              "      <td>So, I am confused! Is Ocrelizumab a clone of R...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  ... sentiment_2\n",
              "0  4b45464468211e25b0ba095b7d9beee2f011939a  ...           1\n",
              "1  67a405445e3e2141895ca34318da9a02e9c2dde7  ...           0\n",
              "2  5a99d2f82fdf8df4d715bb7e6620326a1ce8a112  ...           0\n",
              "3  13f717b1740d24d4322ddf07f76e42e9f9b3f2cc  ...           1\n",
              "4  20bf0873a730336db54199689605645c5f2dc6c3  ...           1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iwuyD4lL4X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = Config(\n",
        "    istesting=False,\n",
        "    seed=12,\n",
        "    batch_size=32,\n",
        "    #lr=3e-4,\n",
        "    lr=0.01,\n",
        "    epochs=80,\n",
        "    hidden_size=32,\n",
        "    max_seq_len=500, \n",
        "    max_vocab_size=10000000,\n",
        "    review_column='text_original',\n",
        "    id_column='unique_hash',\n",
        "    label_column=['sentiment_0','sentiment_1','sentiment_2'],\n",
        "    train_file_name = 'train.csv',\n",
        "    test_file_name = 'test.csv',\n",
        "    data_folder_loc = Path(\"./\"),\n",
        "    token_indexers = ELMoTokenCharactersIndexer(),\n",
        "#   token_indexers = PretrainedBertIndexer(pretrained_model=\"bert-base-uncased\",max_pieces=500,do_lowercase=True,),\n",
        "    bidirectional=True, \n",
        "    batch_first=True,\n",
        "    embeddingtype = 'elmo'\n",
        ")\n",
        "\n",
        "\n",
        "torch.manual_seed(config.seed)\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "#dim = \n",
        "class BertSentencePooler(Seq2VecEncoder):\n",
        "    def forward(self, embs,mask):\n",
        "        return embs[:, 0]\n",
        "    \n",
        "    @overrides\n",
        "    def get_output_dim(self):\n",
        "        return bert_dim\n",
        "\n",
        "class data_setup(SentiDatasetReader):\n",
        "    def __init__(self,config):\n",
        "        self.config = config\n",
        "        super().__init__( token_indexers = self.config.token_indexers,\n",
        "            max_seq_len = self.config.max_seq_len,\n",
        "            review_column = self.config.review_column,\n",
        "            label_column = self.config.label_column,\n",
        "            id_column = self.config.id_column,\n",
        "            istesting = self.config.istesting,\n",
        "            embeddingtype = self.config.embeddingtype)\n",
        "        \n",
        "    def create_test_train_dr(self,filepath,trainfile,testfile,validatefile):\n",
        "        train_ds, test_ds,validate_ds = (self.read(filepath / fname) for fname in [trainfile, \n",
        "                                                                               testfile,validatefile]) \n",
        "        return train_ds,test_ds,validate_ds\n",
        "    \n",
        "    def define_vocab(self,datareader):\n",
        "        vocab = Vocabulary.from_instances(datareader, max_vocab_size=self.config.max_vocab_size)\n",
        "        return vocab\n",
        "    \n",
        "    def define_iterator(self,sort_tuple):\n",
        "        vocab = Vocabulary()\n",
        "        iterator = BucketIterator(batch_size=self.config.batch_size, biggest_batch_first=True,\n",
        "                          sorting_keys=[sort_tuple],\n",
        "                         )\n",
        "        iterator.index_with(vocab)\n",
        "        return iterator\n",
        "    \n",
        "    def define_elmo_embedding(self,options,weights):\n",
        "        #options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
        "        #weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
        "        elmo_embedder = ElmoTokenEmbedder(options, weights)\n",
        "        word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})\n",
        "        return word_embeddings\n",
        "    \n",
        "    def define_bert_embedding(self,pretrained_model=\"bert-base-uncased\"):\n",
        "        bert_embedder = PretrainedBertEmbedder(pretrained_model=pretrained_model,\n",
        "                                               top_layer_only=True,)\n",
        "        word_embeddings = BasicTextFieldEmbedder({\"tokens\": bert_embedder},\n",
        "                                                           allow_unmatched_keys = True)\n",
        "        return word_embeddings\n",
        "    \n",
        "    def define_elmo_encoder(self,word_embeddings):\n",
        "        \n",
        "        encoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), \n",
        "                                                self.config.hidden_size, \n",
        "                                                bidirectional=self.config.bidirectional, \n",
        "                                                batch_first=self.config.batch_first))\n",
        "        return encoder\n",
        "    \n",
        "    def define_bert_encoder(self,bert_dim):\n",
        "        vocab = Vocabulary()\n",
        "        bert_dim = bert_dim\n",
        "        encoder = BertSentencePooler(vocab)\n",
        "        return encoder\n",
        "    \n",
        "     \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFDMVQkmL7Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentModel(Model):\n",
        "    def __init__(self, word_embeddings,encoder,out_sz):\n",
        "        vocab = Vocabulary()\n",
        "        \n",
        "        super().__init__(vocab)\n",
        "        self.word_embeddings = word_embeddings\n",
        "        self.encoder = encoder\n",
        "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
        "        self.loss = nn.BCEWithLogitsLoss()\n",
        "        \n",
        "    def forward(self, tokens,\n",
        "                id, label):\n",
        "        mask = get_text_field_mask(tokens)\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        state = self.encoder(embeddings, mask)\n",
        "        class_logits = self.projection(state)\n",
        "        \n",
        "        output = {\"class_logits\": class_logits}\n",
        "        output[\"loss\"] = self.loss(class_logits, label)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6j4rKfLMPZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv('train.csv',index=False)\n",
        "validate.to_csv('validate.csv',index=False)\n",
        "test['sentiment_0']=0\n",
        "test['sentiment_1']=0\n",
        "test['sentiment_2']=0\n",
        "test.to_csv('test.csv',index=False)\n",
        "sample.to_csv('sample.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwVnJqTKL9fA",
        "colab_type": "code",
        "outputId": "75ce902a-152b-4dfd-f182-9026b0084425",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ds = data_setup(config)\n",
        "filepath = Path(\"./\")\n",
        "trainfile = 'train.csv'\n",
        "testfile = 'test.csv'\n",
        "validatefile = 'validate.csv'\n",
        "#options = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json'\n",
        "#weight = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5'\n",
        "options = '/content/gdrive/My Drive/Studies/innoplexus/elmo_2x4096_512_2048cnn_2xhighway_options.json'\n",
        "weight = '/content/gdrive/My Drive/Studies/innoplexus/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
        "output_class = 3\n",
        "sort_tuple = (\"tokens\",\"num_tokens\")\n",
        "\n",
        "train_ds,test_ds,validate_ds = ds.create_test_train_dr(filepath,trainfile,testfile,validatefile)\n",
        "\n",
        "iterator = ds.define_iterator(sort_tuple)\n",
        "if config.embeddingtype == 'elmo':\n",
        "    elmo_word_embedding = ds.define_elmo_embedding(options,weight)\n",
        "    encoder = ds.define_elmo_encoder(elmo_word_embedding)\n",
        "    \n",
        "    model = SentimentModel(\n",
        "        elmo_word_embedding, \n",
        "        encoder, \n",
        "        output_class\n",
        "    )\n",
        "\n",
        "elif config.embeddingtype == 'bert':\n",
        "    bert_word_embedding = ds.define_bert_embedding()\n",
        "    bert_dim = bert_word_embedding.get_output_dim()\n",
        "    encoder = ds.define_bert_encoder(bert_dim)\n",
        "\n",
        "\n",
        "\n",
        "    model = SentimentModel(\n",
        "        bert_word_embedding, \n",
        "        encoder, \n",
        "        output_class\n",
        "        )\n",
        "else:\n",
        "    print(\"please define embedding type\")\n",
        "\n",
        "\n",
        "\n",
        "#batch = nn_util.move_to_device(batch, 0 if USE_GPU else -1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4224it [00:22, 183.85it/s]\n",
            "2924it [00:16, 175.01it/s]\n",
            "1055it [00:05, 190.18it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6IRh_OhL_iw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
        "#momscheduler  = CosineWithRestarts(optimizer,t_initial=4)\n",
        "#momsche=inverted_triangular(optimizer,cool_down = 10,warm_up = 15)\n",
        "#momscheduler  = NoamLR(optimizer,model_size=config.hidden_size,warmup_steps=20,factor=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2kVOtmKjPW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYDqiNdsMBvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_GPU: \n",
        "    model.cuda() \n",
        "else: model\n",
        "#optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.95)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_ds,\n",
        "    validation_dataset = validate_ds,\n",
        "    cuda_device=0 if USE_GPU else -1,\n",
        "    num_epochs=config.epochs,\n",
        " #   learning_rate_scheduler = momscheduler,\n",
        "    shuffle=True,\n",
        "    patience = 5\n",
        "    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGJDU6RxPKB2",
        "colab_type": "code",
        "outputId": "cd7ae5f5-0e1d-4dad-ea83-f51894bd05f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "metrics = trainer.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.4635 ||: 100%|| 132/132 [02:52<00:00,  1.70s/it]\n",
            "loss: 0.4723 ||: 100%|| 33/33 [00:41<00:00,  2.43s/it]\n",
            "loss: 0.4473 ||: 100%|| 132/132 [02:45<00:00,  1.12s/it]\n",
            "loss: 0.4648 ||: 100%|| 33/33 [00:40<00:00,  2.44s/it]\n",
            "loss: 0.4397 ||: 100%|| 132/132 [02:46<00:00,  1.79s/it]\n",
            "loss: 0.4643 ||: 100%|| 33/33 [00:40<00:00,  2.44s/it]\n",
            "loss: 0.4336 ||: 100%|| 132/132 [02:45<00:00,  1.56s/it]\n",
            "loss: 0.4620 ||: 100%|| 33/33 [00:40<00:00,  2.44s/it]\n",
            "loss: 0.4196 ||: 100%|| 132/132 [02:45<00:00,  1.16s/it]\n",
            "loss: 0.4641 ||: 100%|| 33/33 [00:39<00:00,  2.43s/it]\n",
            "loss: 0.4148 ||: 100%|| 132/132 [02:45<00:00,  1.03s/it]\n",
            "loss: 0.4699 ||: 100%|| 33/33 [00:40<00:00,  2.44s/it]\n",
            "loss: 0.4086 ||: 100%|| 132/132 [02:46<00:00,  1.38it/s]\n",
            "loss: 0.4741 ||: 100%|| 33/33 [00:39<00:00,  2.44s/it]\n",
            "loss: 0.3974 ||: 100%|| 132/132 [02:46<00:00,  1.08s/it]\n",
            "loss: 0.4651 ||: 100%|| 33/33 [00:39<00:00,  2.44s/it]\n",
            "loss: 0.3834 ||: 100%|| 132/132 [02:46<00:00,  1.80s/it]\n",
            "loss: 0.4947 ||: 100%|| 33/33 [00:39<00:00,  2.43s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1Xa-KYRMFLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.iterators import DataIterator\n",
        "from tqdm import tqdm\n",
        "from scipy.special import expit # the sigmoid function\n",
        "\n",
        "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model: Model, iterator: DataIterator,\n",
        "                 cuda_device: int=-1) -> None:\n",
        "        self.model = model\n",
        "        self.iterator = iterator\n",
        "        self.cuda_device = cuda_device\n",
        "        \n",
        "    def _extract_data(self, batch) -> np.ndarray:\n",
        "        out_dict = self.model(**batch)\n",
        "        return expit(tonp(out_dict[\"class_logits\"]))\n",
        "    \n",
        "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
        "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
        "        self.model.eval()\n",
        "        pred_generator_tqdm = tqdm(pred_generator,\n",
        "                                   total=self.iterator.get_num_batches(ds))\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in pred_generator_tqdm:\n",
        "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
        "                preds.append(self._extract_data(batch))\n",
        "        return np.concatenate(preds, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMvjOHS6MHy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from allennlp.data.iterators import BasicIterator\n",
        "# iterate over the dataset without changing its order\n",
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "vocab = Vocabulary()\n",
        "seq_iterator.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjVZCWEdMKCn",
        "colab_type": "code",
        "outputId": "6c5bfcbc-3f34-45b0-abdb-943acdf55959",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "predictor = Predictor(model, seq_iterator, cuda_device=0 if USE_GPU else -1)\n",
        "#train_preds = predictor.predict(train_ds) \n",
        "test_preds = predictor.predict(test_ds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 46/46 [02:39<00:00,  3.33s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFMOXTm_MMxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = test_preds.argmax(axis=1)\n",
        "t1 = pd.DataFrame(t1)\n",
        "#t1.value_counts()\n",
        "t1.columns =['res']\n",
        "\n",
        "t = pd.concat([test,t1],axis=1)\n",
        "t.to_csv('test_pred.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeBE8rEAUyud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVGxo2tKdEiS",
        "colab_type": "code",
        "outputId": "f1a9f516-9421-48f9-bb72-43768822d616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "t.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2924, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXScf-nheOuR",
        "colab_type": "code",
        "outputId": "f9dd00a1-d01b-4e77-f523-64f2c10cc3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sample.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2924, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfiuELlpeQGq",
        "colab_type": "code",
        "outputId": "e07b7275-3a10-4a56-ce86-6cd82f52da20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "sample.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                unique_hash  sentiment\n",
              "0  9e9a8166b84114aca147bf409f6f956635034c08          0\n",
              "1  e747e6822c867571afe7b907b51f0f2ca67b0e1a          0\n",
              "2  50b6d851bcff4f35afe354937949e9948975adf7          0\n",
              "3  7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae          0\n",
              "4  8b37d169dee5bdae27060949242fb54feb6a7f7f          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GQqz0VMeRxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = t[['unique_hash','res']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk8DoWegeWg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.columns=['unique_hash','sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D8WL2F3eba2",
        "colab_type": "code",
        "outputId": "39f41bf1-1a82-4353-f695-65b58b9cb446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "t"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_hash</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9e9a8166b84114aca147bf409f6f956635034c08</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>e747e6822c867571afe7b907b51f0f2ca67b0e1a</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50b6d851bcff4f35afe354937949e9948975adf7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8b37d169dee5bdae27060949242fb54feb6a7f7f</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>b1950d27d94ceff4e9bf8c7d1fd4b11b35ede4d7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>abafc5b6c5aac6f777cf265e5c7dd80fb793e6bc</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>e5550693e72a8335d723ca5fc64da91e1256fb0b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ee8c500f6402331ff12b0b29d943b6d1699a0b8d</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>d261600ba4fc022fac12748845deed56822ff195</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ed1836e3e3597568a9b3d58dcfe8ed7143bba4bd</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4b63c92b430a34abdc659a2ceee6fb353a759502</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>c046fc70caab19d74271855afa4b0fce56eed65d</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>7e6cd0d963891627f809b8b3430817dc08a4671e</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>c1db106d5edc8db4a139acd3532e137903b88dfe</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>58bb0752dd7b4835195f27c975bf4ec27dbf5d06</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17158941d16c145b692b65acdc0098d7cde98fd1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>245536722a649761b30a740031040a937d8b3e0e</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>a62ee194c75afeb7527adc2ac3fc1bf4861b818d</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3b792ab6f0d8cbd690fffd1361c23b6638d47219</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>08837b701a4b7c06272d2205ba3a0a2bb9fc8435</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>4c8c81babeb983eb8b420a0f6d49b7eb0e230c8b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>8019e9a28546fa0e1887844aa8479301e2750986</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>fc74b89e8dd0cc22ab96dad95a488358230fe3f3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>165f60e24b14b3b0ee19e4334701fbee7a06cc1f</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>f1fd1bed04c41117a2c51af38463a6cdfe483325</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>20144ae5f449aa112467d7622d484c7d2fcbc622</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>a1ceb5f6d0b925186d194bdd155f27c6ab16a217</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>cc2872fbb66ec3d00e2bc894571246a645055429</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4c327cd2d678ff430a4489d1b43698d60d73abcf</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2894</th>\n",
              "      <td>561130b9255a4a46023f5ce6d9ae2374c7bd1c50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2895</th>\n",
              "      <td>acf6bea80faf3dba078342f66a9ce8351c02ef60</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2896</th>\n",
              "      <td>6986e1fb247990de93cde29af8c83a09029c9804</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2897</th>\n",
              "      <td>6bf651941b810d41f84877c9602ddf15a09b9382</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2898</th>\n",
              "      <td>672dfcc1fa1c5dddc0b4a49c61f8f852728dc6aa</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2899</th>\n",
              "      <td>cb8616abf1aca5f889d0b6f4ae9536969d6ad5e5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2900</th>\n",
              "      <td>8a4fcfefc6843912a6be51f18bf8c7b825d36e97</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2901</th>\n",
              "      <td>25a23752af4ba3b683d074b20ef8326f3bead778</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2902</th>\n",
              "      <td>5628edb82bbbda51dfe5880437e74021ce359d34</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2903</th>\n",
              "      <td>7d4aaca38c667a5963a77f4bdc2c402c1d46475d</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2904</th>\n",
              "      <td>e1d71fc77f39137e2ca2bddbf188f60298a806f0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2905</th>\n",
              "      <td>4fcf70d5275b4d762d5f9a3a3285d8d545603a41</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2906</th>\n",
              "      <td>066541a05b58de835e616f5dd665befdf8883757</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2907</th>\n",
              "      <td>0a64ad868e3e8ae835207d73eba15b0abf306341</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>239ad9b43b272e13e32927d43576143f4d6a1207</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2909</th>\n",
              "      <td>fd29c11624cedcd362f5093f0bb1b31c288e8f58</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2910</th>\n",
              "      <td>d3f908dd7fa0f39e8fea05e06c689553f3bc9ca5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2911</th>\n",
              "      <td>6056167f150213b0394c63b4119778ccc751181e</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>1992ecb6f13204047039e4928e7619ce5ea161e4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>cb5f464e95c2881f77a914ee7313e8440fa3c921</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2914</th>\n",
              "      <td>04e2cede6d4f8fdf0f632c84bc991a9b5a9c6f94</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2915</th>\n",
              "      <td>b6c5b383282b31dca327caee258565a6726a32bb</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2916</th>\n",
              "      <td>6a6cb6fed029f72bae04b62d9481be3476114b18</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2917</th>\n",
              "      <td>937fca3e61512aaf82764139d01830e569cd45ba</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2918</th>\n",
              "      <td>32e9eca022d634fff808646b97fd18bfd64523de</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2919</th>\n",
              "      <td>ac6e60bec9162ae66effd29a0dc9ad11ff966df6</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2920</th>\n",
              "      <td>12afabb6210825308ead9894916abdfc912d7c43</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2921</th>\n",
              "      <td>021bb88c92a71229288304d691d53c3ff7004e4b</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2922</th>\n",
              "      <td>9936efcb83eded79fe9454df188edd7b96c6109e</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2923</th>\n",
              "      <td>05402df12d6769d7f38ab40e0b81464e65e1df0a</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2924 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   unique_hash  sentiment\n",
              "0     9e9a8166b84114aca147bf409f6f956635034c08          2\n",
              "1     e747e6822c867571afe7b907b51f0f2ca67b0e1a          2\n",
              "2     50b6d851bcff4f35afe354937949e9948975adf7          2\n",
              "3     7f82ec2176ae6ab0b5d20b5ffc767ac829f384ae          2\n",
              "4     8b37d169dee5bdae27060949242fb54feb6a7f7f          2\n",
              "5     b1950d27d94ceff4e9bf8c7d1fd4b11b35ede4d7          2\n",
              "6     abafc5b6c5aac6f777cf265e5c7dd80fb793e6bc          2\n",
              "7     e5550693e72a8335d723ca5fc64da91e1256fb0b          2\n",
              "8     ee8c500f6402331ff12b0b29d943b6d1699a0b8d          2\n",
              "9     d261600ba4fc022fac12748845deed56822ff195          2\n",
              "10    ed1836e3e3597568a9b3d58dcfe8ed7143bba4bd          2\n",
              "11    4b63c92b430a34abdc659a2ceee6fb353a759502          2\n",
              "12    c046fc70caab19d74271855afa4b0fce56eed65d          2\n",
              "13    7e6cd0d963891627f809b8b3430817dc08a4671e          2\n",
              "14    c1db106d5edc8db4a139acd3532e137903b88dfe          2\n",
              "15    58bb0752dd7b4835195f27c975bf4ec27dbf5d06          2\n",
              "16    17158941d16c145b692b65acdc0098d7cde98fd1          2\n",
              "17    245536722a649761b30a740031040a937d8b3e0e          2\n",
              "18    a62ee194c75afeb7527adc2ac3fc1bf4861b818d          2\n",
              "19    3b792ab6f0d8cbd690fffd1361c23b6638d47219          2\n",
              "20    08837b701a4b7c06272d2205ba3a0a2bb9fc8435          2\n",
              "21    4c8c81babeb983eb8b420a0f6d49b7eb0e230c8b          2\n",
              "22    8019e9a28546fa0e1887844aa8479301e2750986          2\n",
              "23    fc74b89e8dd0cc22ab96dad95a488358230fe3f3          2\n",
              "24    165f60e24b14b3b0ee19e4334701fbee7a06cc1f          2\n",
              "25    f1fd1bed04c41117a2c51af38463a6cdfe483325          2\n",
              "26    20144ae5f449aa112467d7622d484c7d2fcbc622          2\n",
              "27    a1ceb5f6d0b925186d194bdd155f27c6ab16a217          1\n",
              "28    cc2872fbb66ec3d00e2bc894571246a645055429          2\n",
              "29    4c327cd2d678ff430a4489d1b43698d60d73abcf          2\n",
              "...                                        ...        ...\n",
              "2894  561130b9255a4a46023f5ce6d9ae2374c7bd1c50          2\n",
              "2895  acf6bea80faf3dba078342f66a9ce8351c02ef60          2\n",
              "2896  6986e1fb247990de93cde29af8c83a09029c9804          2\n",
              "2897  6bf651941b810d41f84877c9602ddf15a09b9382          2\n",
              "2898  672dfcc1fa1c5dddc0b4a49c61f8f852728dc6aa          2\n",
              "2899  cb8616abf1aca5f889d0b6f4ae9536969d6ad5e5          2\n",
              "2900  8a4fcfefc6843912a6be51f18bf8c7b825d36e97          2\n",
              "2901  25a23752af4ba3b683d074b20ef8326f3bead778          2\n",
              "2902  5628edb82bbbda51dfe5880437e74021ce359d34          2\n",
              "2903  7d4aaca38c667a5963a77f4bdc2c402c1d46475d          2\n",
              "2904  e1d71fc77f39137e2ca2bddbf188f60298a806f0          2\n",
              "2905  4fcf70d5275b4d762d5f9a3a3285d8d545603a41          2\n",
              "2906  066541a05b58de835e616f5dd665befdf8883757          0\n",
              "2907  0a64ad868e3e8ae835207d73eba15b0abf306341          2\n",
              "2908  239ad9b43b272e13e32927d43576143f4d6a1207          2\n",
              "2909  fd29c11624cedcd362f5093f0bb1b31c288e8f58          2\n",
              "2910  d3f908dd7fa0f39e8fea05e06c689553f3bc9ca5          2\n",
              "2911  6056167f150213b0394c63b4119778ccc751181e          2\n",
              "2912  1992ecb6f13204047039e4928e7619ce5ea161e4          2\n",
              "2913  cb5f464e95c2881f77a914ee7313e8440fa3c921          2\n",
              "2914  04e2cede6d4f8fdf0f632c84bc991a9b5a9c6f94          2\n",
              "2915  b6c5b383282b31dca327caee258565a6726a32bb          2\n",
              "2916  6a6cb6fed029f72bae04b62d9481be3476114b18          2\n",
              "2917  937fca3e61512aaf82764139d01830e569cd45ba          2\n",
              "2918  32e9eca022d634fff808646b97fd18bfd64523de          2\n",
              "2919  ac6e60bec9162ae66effd29a0dc9ad11ff966df6          2\n",
              "2920  12afabb6210825308ead9894916abdfc912d7c43          2\n",
              "2921  021bb88c92a71229288304d691d53c3ff7004e4b          2\n",
              "2922  9936efcb83eded79fe9454df188edd7b96c6109e          2\n",
              "2923  05402df12d6769d7f38ab40e0b81464e65e1df0a          2\n",
              "\n",
              "[2924 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bufPJM1Seb7t",
        "colab_type": "code",
        "outputId": "39547953-a20e-4aa0-930c-640adf11de3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "t['sentiment'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    2872\n",
              "1      31\n",
              "0      21\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vxy5f_qMef6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.to_csv('test_pred.csv',index=False)\n",
        "t.to_csv('/content/gdrive/My Drive/Studies/innoplexus/test_pred.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O-7XYNwenE8",
        "colab_type": "code",
        "outputId": "575c2820-9814-4264-b1c9-9d7449d78fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "nnjn "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-42d4e93a3a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnnjn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nnjn' is not defined"
          ]
        }
      ]
    }
  ]
}